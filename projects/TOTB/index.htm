
<!DOCTYPE html>
<!-- saved from url=(0042)https://cse.buffalo.edu/~jmeng2/index.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script async="" src="./page_files/analytics.js.download"></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-3974203-1', 'auto'); ga('send', 'pageview');</script>
    
    <title>TOTB</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="../../stylefiles/global.css">
    <link rel="stylesheet" type="text/css" href="../../stylefiles/navigation.css">
	<link rel="stylesheet" type="text/css" href="../../stylefiles/home.css">
	<style>a{ TEXT-DECORATION:none}a:hover{TEXT-DECORATION:underline }</style>
	<!-- <style>a{ TEXT-DECORATION:none }</style>-->   <!-- change style for hyperlink -->
</head>

<body data-gr-c-s-loaded="true">

<style type="text/css">
div img{
  cursor: pointer;
  transition: all 0.6s;
}
div img:hover{
  transform: scale(1.8);
}
.underlinedist{ padding-bottom:3px; border-bottom:1px solid #000} 
</style>


<div class="central_body">
	
	<br>
	
    <font size="6" color="#034f84"><center><b>Transparent Object Tracking Benchmark</b></center></font>

	
    <p style="margin-top:5px;">
	<center>
	<font size="4"> <a href="https://hengfan2010.github.io/" target="https://hengfan2010.github.io/"><font color="#0099ff">Heng Fan</font></a> &nbsp; &nbsp; 
	<font color="#0099ff">Halady Akhilesha Miththanthaya</font>*   &nbsp; &nbsp; 
	<font color="#0099ff">Harshit</font>*             &nbsp; &nbsp; 
	<font color="#0099ff">Siranjiv Ramana Rajan</font>*             &nbsp; &nbsp; 
	<br>
	<font color="#0099ff">Xiaoqiong Liu</font> &nbsp; &nbsp; 
	<font color="#0099ff">Zhilin Zou</font>   &nbsp; &nbsp;
	<a href="https://scholar.google.com/citations?user=wOFhljYAAAAJ&hl=en" target="https://scholar.google.com/citations?user=wOFhljYAAAAJ&hl=en"><font color="#0099ff">Yuewei Lin</font></a>   &nbsp; &nbsp;
	<a href="https://www3.cs.stonybrook.edu/~hling/" target="https://www3.cs.stonybrook.edu/~hling/"><font color="#0099ff">Haibin Ling</font></a>
	</font> 
	<br>
	<br>
	
	<font size="4">University of North Texas &nbsp;&nbsp;&nbsp; &nbsp;&nbsp; Stony Brook University &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; Brookhaven National Laboratory</font>
	<!--<font size="4"> Department of Computer Science, Stony Brook University</font>-->
	</center>
	</p>
	
	
	<HR>
	
	<p style="margin-top:5px;">
	<center>
	<font size="5"> <b>Abstract</b></font> <br>
	</center>
	</p>
	
	<p style="margin-top:5px;text-align:justify">
	<font size="4"> Visual tracking has achieved considerable progress in recent years. However, current research in the field mainly 
	focuses on tracking of opaque objects, while little attention is paid to transparent object tracking. In this paper, we make the 
	first attempt in exploring this problem by proposing a Transparent Object Tracking Benchmark (TOTB). Specifically, TOTB consists 
	of 225 videos (86K frames) from 15 diverse transparent object categories. Each sequence is manually labeled with axis-aligned bounding 
	boxes. To the best of our knowledge, TOTB is the first benchmark dedicated to transparent object tracking. In order to understand how 
	existing trackers perform and to provide comparison for future research on TOTB, we extensively evaluate 25 state-of-the-art tracking 
	algorithms. The evaluation results exhibit that more efforts are needed to improve transparent object tracking. Besides, we observe some 
	nontrivial findings from the evaluation that are discrepant with some common beliefs in opaque object tracking. For example, we find that 
	deeper features are not always good for improvements. Moreover, to encourage future research, we introduce a novel tracker, named TransATOM, 
	which leverages transparency features for tracking and surpasses all 25 evaluated approaches by a large margin. By releasing TOTB, we expect to 
	facilitate future research and application of transparent object tracking in both the academia and industry. </font>
	</p>
    
	<br>
	
	<HR>
	
	<p style="margin-top:5px;">
	<center>
	<font size="5"> <b>Dataset</b></font> <br>
	</center>
	</p>
	
	<center>
	
	<font size="4"> <b><span class="underlinedist">225 Videos (Targets)</span></b></font> 			&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;
	<font size="4"> <b><span class="underlinedist">~86,000 Frames</span></b></font>		&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;
	<font size="4"> <b><span class="underlinedist">15 Transparent Object Categories</span></b></font>		&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;
	<font size="4"> <b><span class="underlinedist">12 Attributes</span></b></font>		
	
	<br><br>
	
	<div id="teaser-videos-container">
        <video width="270"  loop="" autoplay="" playsinline="" muted="" class="figure-img img-fluid" src="./videos/WineGlass_3.mp4"></video>
		<video width="270"  loop="" autoplay="" playsinline="" muted="" class="figure-img img-fluid" src="./videos/GlassSlab_8.mp4"></video>
		<video width="270"  loop="" autoplay="" playsinline="" muted="" class="figure-img img-fluid" src="./videos/Bulb_13.mp4"></video>
		<br>
		<video width="270"  loop="" autoplay="" playsinline="" muted="" class="figure-img img-fluid" src="./videos/GlassBall_7.mp4"></video>
		<video width="270"  loop="" autoplay="" playsinline="" muted="" class="figure-img img-fluid" src="./videos/JuggleBubble_6.mp4"></video>
		<video width="270"  loop="" autoplay="" playsinline="" muted="" class="figure-img img-fluid" src="./videos/Beaker_4.mp4"></video>
    </div>
	Qualitative examples of some of the video sequences contained in TOTB.
	</center>
	<br>
	
	<HR>
	
	
	
	
	<p style="margin-top:5px;">
	<center>
	<font size="5"> <b>A New Baseline: TransATOM</b></font> <br>
	</center>
	</p>
	
	<center>
	<img style="pointer-events: none" src="./pictures/transatom.png" width="750">
	<p style="margin-top:5px;text-align:justify">
	 Comparison between the state-of-the-art ATOM and the proposed new baseline TransATOM which integrates conventional classification 
	 feature and transparency feature (check details in the <a href="https://arxiv.org/abs/2011.10875" target="https://arxiv.org/abs/2011.10875"><font color="#0099ff">paper</font></a>) for better target localization. Both methods use the same IoUNet for target scale estimation.
	</p>
	</center>
	
	<center>
	<img style="pointer-events: none" src="./pictures/cls_results.png" width="550">
	<p style="margin-top:5px;text-align:justify">
	 Classification results of ATOM and TransATOM. We can observe that TransATOM shows better classification results for 
	 locating transparent target objects. The yellow boxes in input images are groundtruth.
	</p>
	</center>
	
	
	<br>
	
	<HR>
	
	<p style="margin-top:5px;">
	<center>
	<font size="5"> <b>Results</b></font> <br>
	</center>
	</p>
	
	<center>
	<img src="./pictures/overall_result.png" width="800">
	<p style="margin-top:5px;">
	 Tracking performance of 25 state-of-the-art trackers and TransATOM on TOTB using precision, normalized precision and success.
	</p>
	</center>
	
	<br>
	
	<center>
	<img src="./pictures/three_atts.png" width="800">
	<p style="margin-top:5px;">
	 Tracking performance of different trackers on the three most common attributes in TOTB including ROT, POC and SV.
	</p>
	</center>
	
	<br>
	
	<center>
	<div id="teaser-videos-container">
        <video width="750"  loop="" autoplay="" playsinline="" muted="" class="figure-img img-fluid" src="./videos/video_results.mp4"></video>
    </div>
	Qualitative tracking results of state-of-the-art trackers and TransATOM on TOTB.
	</center>

	
	
	<HR>
	
	<p style="margin-top:5px;">
	<center>
	<font size="5"> <b>Downloads</b></font> <br>
	</center>
	</p>
	
	<center>
	<a href="https://arxiv.org/abs/2011.10875" target="https://arxiv.org/abs/2011.10875">
		<img style="transform: scale(1)" src="./pictures/paper_thumbnail.png" width="850">
	</a>
	<br>
	<font size="4"> <a href="https://arxiv.org/abs/2011.10875" target="https://arxiv.org/abs/2011.10875"><font color="#0099ff">Paper</font></a>  &nbsp; &nbsp;
	<font size="4"> <a href="https://drive.google.com/file/d/1eIbg5wpBoJbGHgv3g-ucW45g-wfQf_Y6/view?usp=sharing" target="https://drive.google.com/file/d/1eIbg5wpBoJbGHgv3g-ucW45g-wfQf_Y6/view?usp=sharing"><font color="#0099ff">Dataset (google drive~7.8G)</font></a>  &nbsp; &nbsp;
	<!--
	<font size="4"> <font color="#0099ff">Dataset [<a href="https://drive.google.com/file/d/1eIbg5wpBoJbGHgv3g-ucW45g-wfQf_Y6/view?usp=sharing" target="https://arxiv.org/abs/2011.10875"><font color="#0099ff">Google drive</font></a> | Baidu Pan - <a href="https://pan.baidu.com/s/1PsZoZWKioonKkalkiUdt-g" target="#"><font color="#0099ff">part1</font></a> (pwd: TOTB), <a href="https://pan.baidu.com/s/18LUv5k57v6-GVyvdzRHqpg" target="#"><font color="#0099ff">part2</font></a> (pwd: TOTB)]</font>  &nbsp; &nbsp;&nbsp;
	<br>
	-->
	<font size="4"> <a href="./totb_evaluation.zip" target="./totb_evaluation.zip"><font color="#0099ff">Evaluation toolkit</font></a>  &nbsp; &nbsp;
	<font size="4"> <a href="#"><font color="#0099ff">TransATOM code (coming soon ...)</font></a> 
	</center>
	
	<br>
	
	<HR>
	
	<p style="margin-top:5px;">
	<center>
	<font size="5"> <b>Reference</b></font> <br>
	</center>
	</p>
	

	<table align=center width=1100px>
  			<tr>
  	            <td>
  				<left>
					<code>
					@inproceedings{fan2021transparent, <br>
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; title={Transparent Object Tracking Benchmark}, <br>
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; author={Fan, Heng and Miththanthaya, Halady Akhilesha and Harshit and Rajan,  <br>
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Siranjiv Ramana and Liu, Xiaoqiong and Zou, Zhilin and Lin, Yuewei and Ling, Haibin}, <br>
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},,<br>
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; year={2021}<br>
					}
					</code>
				</left>
				</td>
			</tr>
	</table>
	
	<br>

	<HR>
	<b>Contact:</b> If you have any questions, please contact Heng Fan at heng.fan@unt.edu.
	<HR>
	
</div>

</body></html>
